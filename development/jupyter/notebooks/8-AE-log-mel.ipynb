{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Semi-supervised anomaly detection: log mel-spectrogram - model 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook will show how to implement in Tensorflow the AE model used as baseline for [DCASE 2020](http://dcase.community/challenge2020/task-unsupervised-detection-of-anomalous-sounds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load the libraries for this notebook.\r\n",
    "- **Tensorflow dataset** to load the dataset\r\n",
    "- **Tensorflow** to create an AE model\r\n",
    "- **Pandas** to manipulate results\r\n",
    "- **Sklearn** to compute metrics\r\n",
    "- **Plotnine** to plot results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_datasets as tfds\r\n",
    "import tensorflow as tf\r\n",
    "\r\n",
    "from tensorflow.keras.layers import (\r\n",
    "    InputLayer,\r\n",
    "    Dense,\r\n",
    "    BatchNormalization,\r\n",
    "    Activation,\r\n",
    ")\r\n",
    "\r\n",
    "from tensorflow.keras import Sequential\r\n",
    "from tensorflow.keras.optimizers import Adam\r\n",
    "from tensorflow.keras.losses import MeanSquaredError\r\n",
    "\r\n",
    "import numpy as np\r\n",
    "import pandas as pd\r\n",
    "\r\n",
    "import sklearn\r\n",
    "from sklearn.metrics import (\r\n",
    "    confusion_matrix, \r\n",
    "    classification_report,\r\n",
    "    roc_auc_score\r\n",
    ")\r\n",
    "\r\n",
    "import plotnine as p9\r\n",
    "\r\n",
    "import datetime\r\n",
    "\r\n",
    "import os\r\n",
    "\r\n",
    "import warnings\r\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow datasets: 4.2.0\n",
      "Tensorflow: 2.4.1\n",
      "Sklearn: 0.24.2\n",
      "Numpy: 1.19.5\n",
      "Pandas: 1.2.4\n",
      "Plotnine: 0.8.0\n"
     ]
    }
   ],
   "source": [
    "print(f\"Tensorflow datasets: {tfds.__version__}\")\r\n",
    "print(f\"Tensorflow: {tf.__version__}\")\r\n",
    "print(f\"Sklearn: {sklearn.__version__}\")\r\n",
    "print(f\"Numpy: {np.__version__}\")\r\n",
    "print(f\"Pandas: {pd.__version__}\")\r\n",
    "print(f\"Plotnine: {p9.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's set the seed for the Tensorflow dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = tfds.ReadConfig(try_autocache=True, shuffle_seed=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load the dataset and create three sets (train, validation, test). We make the train set (90%) and validation set (10%) from the train data and the test set from the test data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pump\n",
    "data_dir = \"../dataset\"\n",
    "\n",
    "(train, val, test), info = tfds.load(\n",
    "    \"pump\",\n",
    "    split=[\"train[:90%]\", \"train[90%:]\", \"test\"],\n",
    "    data_dir=data_dir,\n",
    "    with_info=True,\n",
    "    shuffle_files=True,\n",
    "    read_config=config,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use 128 log mel-band energies from a spectrogram with an analysis frame of 64 ms and 50% hop size. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = tf.signal.linear_to_mel_weight_matrix(\r\n",
    "    num_mel_bins=128, num_spectrogram_bins=512+1, sample_rate=16_000, dtype=tf.float32\r\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mel(item):\r\n",
    "    audio = tf.cast(item[\"audio\"], tf.float32)\r\n",
    "    audio = audio / 2**15\r\n",
    "\r\n",
    "    # Calculate the STFT of the audio signal\r\n",
    "    stfts = tf.signal.stft(\r\n",
    "            audio,\r\n",
    "            frame_length=1024,\r\n",
    "            frame_step=512,\r\n",
    "            pad_end=False,  # librosa test compatibility\r\n",
    "        )\r\n",
    "    # Get Magnitude fo the STFT\r\n",
    "    mag_stfts = tf.abs(stfts)\r\n",
    "\r\n",
    "    # Get the mel-spectrogram\r\n",
    "    melgrams = tf.tensordot(\r\n",
    "            tf.square(mag_stfts), A, axes=1\r\n",
    "    )\r\n",
    "\r\n",
    "    # Change of base for logarithmics: from natural logarithmic to common logarithmic \r\n",
    "    def _tf_log10(x):\r\n",
    "        numerator = tf.math.log(x)\r\n",
    "        denominator = tf.math.log(tf.constant(10, dtype=numerator.dtype))\r\n",
    "        return numerator / denominator\r\n",
    "\r\n",
    "    # Calculate the log-mel spectrogram    \r\n",
    "    log_melgrams = 20 / 2 * _tf_log10(melgrams + 10e-6)\r\n",
    "\r\n",
    "    # Concat 5 time frames together to feed the model\r\n",
    "    concat_melgrams = tf.concat(\r\n",
    "        [\r\n",
    "            tf.roll(log_melgrams, shift=1, axis=0),\r\n",
    "            tf.roll(log_melgrams, shift=2, axis=0),\r\n",
    "            log_melgrams,\r\n",
    "            tf.roll(log_melgrams, shift=-1, axis=0),\r\n",
    "            tf.roll(log_melgrams, shift=-2, axis=0)\r\n",
    "        ],\r\n",
    "        axis=1,\r\n",
    "    )\r\n",
    "    concat_melgrams = concat_melgrams[2:-2,:]\r\n",
    "\r\n",
    "    item[\"audio\"] = concat_melgrams\r\n",
    "    return item"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's prepare the sets for training. AE models need that the input and the output be the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_train(item):\r\n",
    "    return item[\"audio\"], item[\"audio\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 512\n",
    "SHUFFLE_BUFFER_SIZE = 1024\n",
    "\n",
    "train = train.map(mel)\n",
    "train2 = train.map(prep_train).batch(BATCH_SIZE)\n",
    "\n",
    "val = train.map(mel)\n",
    "val2 = train.map(prep_train).batch(BATCH_SIZE)\n",
    "\n",
    "test = test.map(mel)\n",
    "test2 = test.batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the same AE model described used as baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder = Sequential(\r\n",
    "    [\r\n",
    "        InputLayer(input_shape=(307, 640)),\r\n",
    "        Dense(128),\r\n",
    "        BatchNormalization(),\r\n",
    "        Activation('relu'),\r\n",
    "        Dense(128),\r\n",
    "        BatchNormalization(),\r\n",
    "        Activation('relu'),\r\n",
    "        Dense(128),\r\n",
    "        BatchNormalization(),\r\n",
    "        Activation('relu'),\r\n",
    "        Dense(128),\r\n",
    "        BatchNormalization(),\r\n",
    "        Activation('relu'),\r\n",
    "        Dense(8),\r\n",
    "        BatchNormalization(),\r\n",
    "        Activation('relu'),\r\n",
    "        Dense(128),\r\n",
    "        BatchNormalization(),\r\n",
    "        Activation('relu'),\r\n",
    "        Dense(128),\r\n",
    "        BatchNormalization(),\r\n",
    "        Activation('relu'),\r\n",
    "        Dense(128),\r\n",
    "        BatchNormalization(),\r\n",
    "        Activation('relu'),\r\n",
    "        Dense(128),\r\n",
    "        BatchNormalization(),\r\n",
    "        Activation('relu'),\r\n",
    "        Dense(640)\r\n",
    "    ]\r\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 307, 128)          82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 307, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 307, 128)          0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 307, 128)          16512     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 307, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 307, 128)          0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 307, 128)          16512     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 307, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 307, 128)          0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 307, 128)          16512     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 307, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 307, 128)          0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 307, 8)            1032      \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 307, 8)            32        \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 307, 8)            0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 307, 128)          1152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 307, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 307, 128)          0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 307, 128)          16512     \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 307, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 307, 128)          0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 307, 128)          16512     \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 307, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 307, 128)          0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 307, 128)          16512     \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 307, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 307, 128)          0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 307, 640)          82560     \n",
      "=================================================================\n",
      "Total params: 269,992\n",
      "Trainable params: 267,928\n",
      "Non-trainable params: 2,064\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use same parameters as the paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.compile(optimizer=Adam(learning_rate=0.001), loss=MeanSquaredError())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a Tensorboard callback to check the results in Tensorboard and a ModelCheckpoint callback to save the best model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = os.path.join('..', 'logs', 'semi-mel', datetime.datetime.now().strftime('%Y%m%d-%H%M%S'))\n",
    "tb_callback = tf.keras.callbacks.TensorBoard(\n",
    "    log_dir, update_freq=1, histogram_freq=1, write_graph=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_filepath = os.path.join(\"tmp\", \"semi-mel\", \"checkpoint\")\n",
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    save_weights_only=True,\n",
    "    monitor='val_loss',\n",
    "    mode='min',\n",
    "    save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "6/6 [==============================] - 61s 10s/step - loss: 222.7778 - val_loss: 221.6551\n",
      "Epoch 2/100\n",
      "6/6 [==============================] - 56s 10s/step - loss: 214.5587 - val_loss: 212.7692\n",
      "Epoch 3/100\n",
      "6/6 [==============================] - 56s 10s/step - loss: 203.4214 - val_loss: 193.7221\n",
      "Epoch 4/100\n",
      "6/6 [==============================] - 55s 10s/step - loss: 191.7568 - val_loss: 165.1941\n",
      "Epoch 5/100\n",
      "6/6 [==============================] - 55s 10s/step - loss: 180.6123 - val_loss: 130.0419\n",
      "Epoch 6/100\n",
      "6/6 [==============================] - 55s 10s/step - loss: 168.6672 - val_loss: 118.1894\n",
      "Epoch 7/100\n",
      "6/6 [==============================] - 55s 10s/step - loss: 159.7115 - val_loss: 113.8179\n",
      "Epoch 8/100\n",
      "6/6 [==============================] - 55s 10s/step - loss: 149.2696 - val_loss: 102.8414\n",
      "Epoch 9/100\n",
      "6/6 [==============================] - 55s 10s/step - loss: 137.9536 - val_loss: 103.0131\n",
      "Epoch 10/100\n",
      "6/6 [==============================] - 55s 10s/step - loss: 128.8833 - val_loss: 103.8253\n",
      "Epoch 11/100\n",
      "6/6 [==============================] - 57s 10s/step - loss: 119.8052 - val_loss: 88.5706\n",
      "Epoch 12/100\n",
      "6/6 [==============================] - 56s 10s/step - loss: 111.4188 - val_loss: 91.5000\n",
      "Epoch 13/100\n",
      "6/6 [==============================] - 58s 10s/step - loss: 102.6275 - val_loss: 77.6114\n",
      "Epoch 14/100\n",
      "6/6 [==============================] - 58s 10s/step - loss: 94.5658 - val_loss: 83.3295\n",
      "Epoch 15/100\n",
      "6/6 [==============================] - 57s 10s/step - loss: 86.7370 - val_loss: 81.5289\n",
      "Epoch 16/100\n",
      "6/6 [==============================] - 58s 10s/step - loss: 79.8526 - val_loss: 74.1256\n",
      "Epoch 17/100\n",
      "6/6 [==============================] - 57s 10s/step - loss: 73.8585 - val_loss: 73.9493\n",
      "Epoch 18/100\n",
      "6/6 [==============================] - 57s 10s/step - loss: 67.7077 - val_loss: 70.6268\n",
      "Epoch 19/100\n",
      "6/6 [==============================] - 57s 10s/step - loss: 61.9431 - val_loss: 59.6652\n",
      "Epoch 20/100\n",
      "6/6 [==============================] - 57s 10s/step - loss: 57.0829 - val_loss: 58.9264\n",
      "Epoch 21/100\n",
      "6/6 [==============================] - 56s 10s/step - loss: 52.8343 - val_loss: 58.9135\n",
      "Epoch 22/100\n",
      "6/6 [==============================] - 57s 10s/step - loss: 48.4489 - val_loss: 52.5205\n",
      "Epoch 23/100\n",
      "6/6 [==============================] - 57s 10s/step - loss: 44.5485 - val_loss: 48.4507\n",
      "Epoch 24/100\n",
      "6/6 [==============================] - 57s 10s/step - loss: 41.1954 - val_loss: 45.9592\n",
      "Epoch 25/100\n",
      "6/6 [==============================] - 57s 10s/step - loss: 38.2407 - val_loss: 42.8817\n",
      "Epoch 26/100\n",
      "6/6 [==============================] - 57s 10s/step - loss: 35.7248 - val_loss: 41.8096\n",
      "Epoch 27/100\n",
      "6/6 [==============================] - 56s 10s/step - loss: 33.5460 - val_loss: 34.8965\n",
      "Epoch 28/100\n",
      "6/6 [==============================] - 56s 10s/step - loss: 31.7603 - val_loss: 37.0147\n",
      "Epoch 29/100\n",
      "6/6 [==============================] - 56s 10s/step - loss: 30.0888 - val_loss: 37.6719\n",
      "Epoch 30/100\n",
      "6/6 [==============================] - 57s 10s/step - loss: 28.4935 - val_loss: 35.2291\n",
      "Epoch 31/100\n",
      "6/6 [==============================] - 58s 10s/step - loss: 27.4790 - val_loss: 35.1754\n",
      "Epoch 32/100\n",
      "6/6 [==============================] - 57s 10s/step - loss: 26.3156 - val_loss: 31.4611\n",
      "Epoch 33/100\n",
      "6/6 [==============================] - 57s 10s/step - loss: 25.5183 - val_loss: 30.0608\n",
      "Epoch 34/100\n",
      "6/6 [==============================] - 57s 10s/step - loss: 24.9272 - val_loss: 30.2799\n",
      "Epoch 35/100\n",
      "6/6 [==============================] - 56s 10s/step - loss: 24.2269 - val_loss: 29.1653\n",
      "Epoch 36/100\n",
      "6/6 [==============================] - 55s 9s/step - loss: 23.7001 - val_loss: 28.1617\n",
      "Epoch 37/100\n",
      "6/6 [==============================] - 51s 9s/step - loss: 23.3849 - val_loss: 26.9677\n",
      "Epoch 38/100\n",
      "6/6 [==============================] - 49s 9s/step - loss: 23.3057 - val_loss: 27.5058\n",
      "Epoch 39/100\n",
      "6/6 [==============================] - 49s 8s/step - loss: 22.5844 - val_loss: 27.7353\n",
      "Epoch 40/100\n",
      "6/6 [==============================] - 51s 9s/step - loss: 22.3507 - val_loss: 25.8926\n",
      "Epoch 41/100\n",
      "6/6 [==============================] - 51s 9s/step - loss: 22.1893 - val_loss: 26.0711\n",
      "Epoch 42/100\n",
      "6/6 [==============================] - 51s 9s/step - loss: 22.0304 - val_loss: 25.6964\n",
      "Epoch 43/100\n",
      "6/6 [==============================] - 50s 9s/step - loss: 21.9096 - val_loss: 25.6576\n",
      "Epoch 44/100\n",
      "6/6 [==============================] - 50s 9s/step - loss: 21.7483 - val_loss: 25.6879\n",
      "Epoch 45/100\n",
      "6/6 [==============================] - 50s 9s/step - loss: 21.5716 - val_loss: 25.7397\n",
      "Epoch 46/100\n",
      "6/6 [==============================] - 50s 9s/step - loss: 21.6923 - val_loss: 25.5148\n",
      "Epoch 47/100\n",
      "6/6 [==============================] - 50s 9s/step - loss: 21.3924 - val_loss: 26.1045\n",
      "Epoch 48/100\n",
      "6/6 [==============================] - 50s 9s/step - loss: 21.3805 - val_loss: 26.3757\n",
      "Epoch 49/100\n",
      "6/6 [==============================] - 50s 9s/step - loss: 21.2959 - val_loss: 25.6874\n",
      "Epoch 50/100\n",
      "6/6 [==============================] - 50s 9s/step - loss: 21.2756 - val_loss: 25.1545\n",
      "Epoch 51/100\n",
      "6/6 [==============================] - 50s 9s/step - loss: 21.1495 - val_loss: 25.3546\n",
      "Epoch 52/100\n",
      "6/6 [==============================] - 50s 9s/step - loss: 21.1751 - val_loss: 25.9150\n",
      "Epoch 53/100\n",
      "6/6 [==============================] - 50s 9s/step - loss: 21.0998 - val_loss: 25.7309\n",
      "Epoch 54/100\n",
      "6/6 [==============================] - 50s 9s/step - loss: 21.0598 - val_loss: 25.2527\n",
      "Epoch 55/100\n",
      "6/6 [==============================] - 50s 9s/step - loss: 20.8795 - val_loss: 25.4366\n",
      "Epoch 56/100\n",
      "6/6 [==============================] - 53s 9s/step - loss: 20.9530 - val_loss: 25.1492\n",
      "Epoch 57/100\n",
      "6/6 [==============================] - 53s 9s/step - loss: 20.8361 - val_loss: 24.7956\n",
      "Epoch 58/100\n",
      "6/6 [==============================] - 51s 9s/step - loss: 20.8577 - val_loss: 24.5204\n",
      "Epoch 59/100\n",
      "6/6 [==============================] - 52s 9s/step - loss: 20.6551 - val_loss: 24.9706\n",
      "Epoch 60/100\n",
      "6/6 [==============================] - 51s 9s/step - loss: 20.7118 - val_loss: 24.4218\n",
      "Epoch 61/100\n",
      "6/6 [==============================] - 51s 9s/step - loss: 20.6821 - val_loss: 24.2204\n",
      "Epoch 62/100\n",
      "6/6 [==============================] - 54s 9s/step - loss: 20.5192 - val_loss: 23.8539\n",
      "Epoch 63/100\n",
      "6/6 [==============================] - 51s 9s/step - loss: 20.5702 - val_loss: 23.6124\n",
      "Epoch 64/100\n",
      "6/6 [==============================] - 51s 9s/step - loss: 20.5971 - val_loss: 23.2011\n",
      "Epoch 65/100\n",
      "6/6 [==============================] - 51s 9s/step - loss: 20.4295 - val_loss: 22.7923\n",
      "Epoch 66/100\n",
      "6/6 [==============================] - 55s 10s/step - loss: 20.4213 - val_loss: 22.7013\n",
      "Epoch 67/100\n",
      "6/6 [==============================] - 51s 9s/step - loss: 20.3070 - val_loss: 22.4448\n",
      "Epoch 68/100\n",
      "6/6 [==============================] - 51s 9s/step - loss: 20.2791 - val_loss: 22.2501\n",
      "Epoch 69/100\n",
      "6/6 [==============================] - 51s 9s/step - loss: 20.1514 - val_loss: 21.7646\n",
      "Epoch 70/100\n",
      "6/6 [==============================] - 51s 9s/step - loss: 20.1898 - val_loss: 21.6334\n",
      "Epoch 71/100\n",
      "6/6 [==============================] - 55s 9s/step - loss: 20.2387 - val_loss: 21.4269\n",
      "Epoch 72/100\n",
      "6/6 [==============================] - 51s 9s/step - loss: 20.1340 - val_loss: 21.4088\n",
      "Epoch 73/100\n",
      "6/6 [==============================] - 50s 9s/step - loss: 20.1177 - val_loss: 21.3572\n",
      "Epoch 74/100\n",
      "6/6 [==============================] - 51s 9s/step - loss: 19.9349 - val_loss: 21.2151\n",
      "Epoch 75/100\n",
      "6/6 [==============================] - 53s 9s/step - loss: 20.0179 - val_loss: 21.2141\n",
      "Epoch 76/100\n",
      "6/6 [==============================] - 60s 10s/step - loss: 19.8522 - val_loss: 21.0743\n",
      "Epoch 77/100\n",
      "6/6 [==============================] - 58s 10s/step - loss: 19.8648 - val_loss: 21.0212\n",
      "Epoch 78/100\n",
      "6/6 [==============================] - 58s 10s/step - loss: 19.7676 - val_loss: 20.8222\n",
      "Epoch 79/100\n",
      "6/6 [==============================] - 58s 10s/step - loss: 19.7478 - val_loss: 20.8968\n",
      "Epoch 80/100\n",
      "6/6 [==============================] - 58s 10s/step - loss: 19.7564 - val_loss: 20.8792\n",
      "Epoch 81/100\n",
      "6/6 [==============================] - 58s 10s/step - loss: 19.6724 - val_loss: 20.6737\n",
      "Epoch 82/100\n",
      "6/6 [==============================] - 60s 10s/step - loss: 19.6032 - val_loss: 20.6489\n",
      "Epoch 83/100\n",
      "6/6 [==============================] - 59s 10s/step - loss: 19.5022 - val_loss: 20.5292\n",
      "Epoch 84/100\n",
      "6/6 [==============================] - 59s 10s/step - loss: 19.4975 - val_loss: 20.5101\n",
      "Epoch 85/100\n",
      "6/6 [==============================] - 59s 10s/step - loss: 19.4861 - val_loss: 20.3917\n",
      "Epoch 86/100\n",
      "6/6 [==============================] - 59s 10s/step - loss: 19.3872 - val_loss: 20.2184\n",
      "Epoch 87/100\n",
      "6/6 [==============================] - 59s 10s/step - loss: 19.3690 - val_loss: 20.1819\n",
      "Epoch 88/100\n",
      "6/6 [==============================] - 58s 10s/step - loss: 19.3257 - val_loss: 20.0879\n",
      "Epoch 89/100\n",
      "6/6 [==============================] - 58s 10s/step - loss: 19.2660 - val_loss: 20.1360\n",
      "Epoch 90/100\n",
      "6/6 [==============================] - 58s 10s/step - loss: 19.2660 - val_loss: 20.0111\n",
      "Epoch 91/100\n",
      "6/6 [==============================] - 57s 10s/step - loss: 19.1565 - val_loss: 19.9673\n",
      "Epoch 92/100\n",
      "6/6 [==============================] - 58s 10s/step - loss: 19.1464 - val_loss: 19.8857\n",
      "Epoch 93/100\n",
      "6/6 [==============================] - 60s 10s/step - loss: 19.0243 - val_loss: 19.6607\n",
      "Epoch 94/100\n",
      "6/6 [==============================] - 59s 10s/step - loss: 19.0330 - val_loss: 19.6633\n",
      "Epoch 95/100\n",
      "6/6 [==============================] - 59s 10s/step - loss: 19.0483 - val_loss: 19.5740\n",
      "Epoch 96/100\n",
      "6/6 [==============================] - 58s 10s/step - loss: 18.9387 - val_loss: 19.5335\n",
      "Epoch 97/100\n",
      "6/6 [==============================] - 59s 10s/step - loss: 18.9348 - val_loss: 19.4610\n",
      "Epoch 98/100\n",
      "6/6 [==============================] - 59s 10s/step - loss: 18.9915 - val_loss: 19.5056\n",
      "Epoch 99/100\n",
      "6/6 [==============================] - 58s 10s/step - loss: 18.9091 - val_loss: 19.3817\n",
      "Epoch 100/100\n",
      "6/6 [==============================] - 58s 10s/step - loss: 18.8426 - val_loss: 19.3267\n"
     ]
    }
   ],
   "source": [
    "history = autoencoder.fit(\r\n",
    "    train2,\r\n",
    "    epochs=100,\r\n",
    "    shuffle=True,\r\n",
    "    validation_data=val2,\r\n",
    "    callbacks=[tb_callback, model_checkpoint_callback],\r\n",
    "    verbose=1,\r\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's join train and test set together for faster predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "audios = train.concatenate(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = autoencoder.predict(audios.map(lambda item: item[\"audio\"]).batch(BATCH_SIZE))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's compute the reconstruction error for all audios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_lst = []\r\n",
    "for item, pred in zip(tfds.as_numpy(audios), pred):\r\n",
    "    error = np.mean(np.square(item[\"audio\"] - pred))\r\n",
    "    error_lst.append(error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To check how the model behaves, we can tranform the Tensorflow dataset into a dataframe and add the previous computed reconstruction error to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>audio</th>\n      <th>id</th>\n      <th>machine_id</th>\n      <th>split</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1757</th>\n      <td>[[-3.04029, -3.5188432, -4.4411397, -3.3230824...</td>\n      <td>0462</td>\n      <td>00</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1859</th>\n      <td>[[3.376, 4.0787582, 6.522976, 3.2917256, -1.46...</td>\n      <td>0363</td>\n      <td>00</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>229</th>\n      <td>[[-11.679119, -12.636805, -17.260406, -23.9582...</td>\n      <td>0857</td>\n      <td>00</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2366</th>\n      <td>[[-14.110062, -15.339539, -27.698782, -14.4990...</td>\n      <td>0058</td>\n      <td>00</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1683</th>\n      <td>[[-7.402933, -8.136212, -10.589108, -2.9100976...</td>\n      <td>0019</td>\n      <td>00</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "                                                  audio    id machine_id  \\\n1757  [[-3.04029, -3.5188432, -4.4411397, -3.3230824...  0462         00   \n1859  [[3.376, 4.0787582, 6.522976, 3.2917256, -1.46...  0363         00   \n229   [[-11.679119, -12.636805, -17.260406, -23.9582...  0857         00   \n2366  [[-14.110062, -15.339539, -27.698782, -14.4990...  0058         00   \n1683  [[-7.402933, -8.136212, -10.589108, -2.9100976...  0019         00   \n\n     split label  \n1757     0     0  \n1859     0     0  \n229      0     0  \n2366     0     0  \n1683     0     0  "
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audios_df = tfds.as_dataframe(audios, info)\n",
    "\n",
    "# Convert byte-type texts to string-type texts\n",
    "for col in audios_df:\n",
    "    if isinstance(audios_df[col][0], bytes):\n",
    "        audios_df[col] = audios_df[col].str.decode(\"utf8\")\n",
    "\n",
    "dct_columns = {\n",
    "    \"audio/id\": \"id\", \n",
    "    \"audio/machine\": \"machine_id\", \n",
    "    \"audio/split\": \"split\",\n",
    "}\n",
    "\n",
    "# Convert object-type columns to a more convenient data type\n",
    "dct_types = {\n",
    "    \"id\": \"string\",\n",
    "    \"machine_id\": \"category\",\n",
    "    \"split\": \"category\",\n",
    "    \"label\": \"category\",\n",
    "}\n",
    "\n",
    "audios_df = (\n",
    "    audios_df\n",
    "    .rename(columns=dct_columns)\n",
    "    .astype(dct_types)\n",
    ")\n",
    "\n",
    "audios_df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "audios_df[\"error\"] = error_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>audio</th>\n      <th>id</th>\n      <th>machine_id</th>\n      <th>split</th>\n      <th>label</th>\n      <th>error</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2500</th>\n      <td>[[-15.055285, -14.061519, -11.157044, -1.05378...</td>\n      <td>0829</td>\n      <td>02</td>\n      <td>0</td>\n      <td>0</td>\n      <td>41.018757</td>\n    </tr>\n    <tr>\n      <th>3361</th>\n      <td>[[-1.6490643, -0.27319902, 3.1322317, -0.18713...</td>\n      <td>0089</td>\n      <td>00</td>\n      <td>1</td>\n      <td>1</td>\n      <td>33.193142</td>\n    </tr>\n    <tr>\n      <th>648</th>\n      <td>[[-15.040683, -14.947614, -13.811647, -5.13650...</td>\n      <td>0270</td>\n      <td>02</td>\n      <td>0</td>\n      <td>0</td>\n      <td>26.648193</td>\n    </tr>\n    <tr>\n      <th>1728</th>\n      <td>[[-11.432711, -10.505246, -7.6987658, -7.82518...</td>\n      <td>0038</td>\n      <td>04</td>\n      <td>0</td>\n      <td>0</td>\n      <td>20.967920</td>\n    </tr>\n    <tr>\n      <th>2448</th>\n      <td>[[-11.697044, -10.087462, -6.420618, -3.416823...</td>\n      <td>0401</td>\n      <td>02</td>\n      <td>0</td>\n      <td>0</td>\n      <td>22.544340</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "                                                  audio    id machine_id  \\\n2500  [[-15.055285, -14.061519, -11.157044, -1.05378...  0829         02   \n3361  [[-1.6490643, -0.27319902, 3.1322317, -0.18713...  0089         00   \n648   [[-15.040683, -14.947614, -13.811647, -5.13650...  0270         02   \n1728  [[-11.432711, -10.505246, -7.6987658, -7.82518...  0038         04   \n2448  [[-11.697044, -10.087462, -6.420618, -3.416823...  0401         02   \n\n     split label      error  \n2500     0     0  41.018757  \n3361     1     1  33.193142  \n648      0     0  26.648193  \n1728     0     0  20.967920  \n2448     0     0  22.544340  "
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audios_df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead tr th {\n        text-align: left;\n    }\n\n    .dataframe thead tr:last-of-type th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr>\n      <th></th>\n      <th colspan=\"2\" halign=\"left\">error</th>\n    </tr>\n    <tr>\n      <th></th>\n      <th>mean</th>\n      <th>std</th>\n    </tr>\n    <tr>\n      <th>machine_id</th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>00</th>\n      <td>33.282516</td>\n      <td>14.097515</td>\n    </tr>\n    <tr>\n      <th>02</th>\n      <td>32.918655</td>\n      <td>15.178963</td>\n    </tr>\n    <tr>\n      <th>04</th>\n      <td>34.205400</td>\n      <td>16.445124</td>\n    </tr>\n    <tr>\n      <th>06</th>\n      <td>32.817989</td>\n      <td>12.519745</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "                error           \n                 mean        std\nmachine_id                      \n00          33.282516  14.097515\n02          32.918655  15.178963\n04          34.205400  16.445124\n06          32.817989  12.519745"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(\n",
    "    audios_df\n",
    "    .query(\"split == 0\")\n",
    "    .groupby(\"machine_id\")\n",
    "    .agg({\"error\": [\"mean\", \"std\"]})\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead tr th {\n        text-align: left;\n    }\n\n    .dataframe thead tr:last-of-type th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr>\n      <th></th>\n      <th></th>\n      <th colspan=\"2\" halign=\"left\">error</th>\n    </tr>\n    <tr>\n      <th></th>\n      <th></th>\n      <th>mean</th>\n      <th>std</th>\n    </tr>\n    <tr>\n      <th>label</th>\n      <th>machine_id</th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th rowspan=\"4\" valign=\"top\">0</th>\n      <th>00</th>\n      <td>39.481560</td>\n      <td>20.855317</td>\n    </tr>\n    <tr>\n      <th>02</th>\n      <td>37.584921</td>\n      <td>16.674927</td>\n    </tr>\n    <tr>\n      <th>04</th>\n      <td>37.952985</td>\n      <td>14.877208</td>\n    </tr>\n    <tr>\n      <th>06</th>\n      <td>42.101414</td>\n      <td>22.763874</td>\n    </tr>\n    <tr>\n      <th rowspan=\"4\" valign=\"top\">1</th>\n      <th>00</th>\n      <td>42.980976</td>\n      <td>22.355795</td>\n    </tr>\n    <tr>\n      <th>02</th>\n      <td>41.256875</td>\n      <td>22.736207</td>\n    </tr>\n    <tr>\n      <th>04</th>\n      <td>37.791416</td>\n      <td>17.864098</td>\n    </tr>\n    <tr>\n      <th>06</th>\n      <td>37.364892</td>\n      <td>15.108028</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "                      error           \n                       mean        std\nlabel machine_id                      \n0     00          39.481560  20.855317\n      02          37.584921  16.674927\n      04          37.952985  14.877208\n      06          42.101414  22.763874\n1     00          42.980976  22.355795\n      02          41.256875  22.736207\n      04          37.791416  17.864098\n      06          37.364892  15.108028"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(\n",
    "    audios_df\n",
    "    .query(\"split == 1\")\n",
    "    .groupby([\"label\", \"machine_id\"])\n",
    "    .agg({\"error\": [\"mean\", \"std\"]})\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems this model can't distinguish anomaly sound from normal sounds very well.\r\n",
    "\r\n",
    "Let's plot the a histogram of the construction error per machine to see more clear."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": "<Figure size 640x480 with 4 Axes>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "p = (\n",
    "    p9.ggplot(audios_df.query(\"split == 1\"), p9.aes(x=\"error\", fill=\"label\"))\n",
    "    + p9.geom_histogram(\n",
    "        p9.aes(y=\"stat(count)\"), position=\"identity\", alpha=0.75\n",
    "    )\n",
    "    + p9.scale_x_continuous(name=\"Reconstruction error\")\n",
    "    + p9.scale_y_continuous(name=\"Count\")\n",
    "    + p9.labs(\n",
    "        title=\"Histogram of reconstruction error\",\n",
    "    )\n",
    "    + p9.scale_fill_brewer(type=\"qualitative\", palette=\"Accent\") \n",
    "    + p9.facet_grid(\"machine_id ~ .\", scales=\"free\")\n",
    "    + p9.theme_bw()\n",
    "    + p9.theme(\n",
    "        panel_border=p9.element_rect(colour=\"black\", fill=None, size=0.5),\n",
    "        axis_text_x=p9.element_text(colour=\"black\", size=9),\n",
    "        axis_text_y=p9.element_text(colour=\"black\", size=9),\n",
    "        legend_key=p9.element_blank(),\n",
    "        legend_title=p9.element_blank(),\n",
    "        panel_grid_major=p9.element_line(colour=\"#d3d3d3\"),\n",
    "        panel_grid_minor=p9.element_blank(),\n",
    "        panel_background=p9.element_blank(),\n",
    "        plot_title=p9.element_text(size=14, family=\"Tahoma\", face=\"bold\"),\n",
    "        text=p9.element_text(family=\"Tahoma\"),\n",
    "    )\n",
    ")\n",
    "\n",
    "print(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Histograms show more clear that the model can't differentiate anomaly audios from normal audio very well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This [AWS](https://aws.amazon.com/es/blogs/machine-learning/performing-anomaly-detection-on-industrial-equipment-using-audio-signals/) post shows how the histogram from a good model should look like.\r\n",
    "\r\n",
    "![Better model](https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2020/12/22/ML-1479-4.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how bad our model is. To distinguish anomaly audios from normal audios, we set the threshold one standard deviation above the mean of the train set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg = (\r\n",
    "    audios_df\r\n",
    "    .query(\"split == 0\")\r\n",
    "    [\"error\"]\r\n",
    "    .mean()\r\n",
    ")\r\n",
    "\r\n",
    "std = (\r\n",
    "    audios_df\r\n",
    "    .query(\"split == 0\")\r\n",
    "    [\"error\"]\r\n",
    "    .std()\r\n",
    ")\r\n",
    "\r\n",
    "threshold = avg + std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a new column with the predicted label based on the threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47.659890841647126\n"
     ]
    }
   ],
   "source": [
    "print(threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>audio</th>\n      <th>id</th>\n      <th>machine_id</th>\n      <th>split</th>\n      <th>label</th>\n      <th>error</th>\n      <th>label_pred</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>[[-4.487632, -5.356105, -8.969563, 0.9362756, ...</td>\n      <td>0811</td>\n      <td>02</td>\n      <td>0</td>\n      <td>0</td>\n      <td>27.111467</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>[[-3.4570742, -1.7174281, 2.0827863, -6.854372...</td>\n      <td>0144</td>\n      <td>00</td>\n      <td>0</td>\n      <td>0</td>\n      <td>33.474049</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>[[-18.791222, -12.935072, -7.0691338, 1.115096...</td>\n      <td>0773</td>\n      <td>06</td>\n      <td>0</td>\n      <td>0</td>\n      <td>43.369644</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>[[-2.9446628, -2.0784752, 0.634026, -0.0055954...</td>\n      <td>0425</td>\n      <td>02</td>\n      <td>0</td>\n      <td>0</td>\n      <td>43.816982</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>[[-0.97368175, -1.4708502, -2.4858472, -13.992...</td>\n      <td>0191</td>\n      <td>04</td>\n      <td>0</td>\n      <td>0</td>\n      <td>20.296885</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "                                               audio    id machine_id split  \\\n0  [[-4.487632, -5.356105, -8.969563, 0.9362756, ...  0811         02     0   \n1  [[-3.4570742, -1.7174281, 2.0827863, -6.854372...  0144         00     0   \n2  [[-18.791222, -12.935072, -7.0691338, 1.115096...  0773         06     0   \n3  [[-2.9446628, -2.0784752, 0.634026, -0.0055954...  0425         02     0   \n4  [[-0.97368175, -1.4708502, -2.4858472, -13.992...  0191         04     0   \n\n  label      error  label_pred  \n0     0  27.111467           0  \n1     0  33.474049           0  \n2     0  43.369644           0  \n3     0  43.816982           0  \n4     0  20.296885           0  "
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audios_df[\"label_pred\"] = audios_df[\"error\"] > threshold\r\n",
    "\r\n",
    "audios_df = audios_df.astype({\"label_pred\": \"int\"})\r\n",
    "audios_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's show the precision, recall, f1-score and roc-auc score for the four machines."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Machine_id=00"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      0.78      0.56       100\n",
      "           1       0.65      0.28      0.39       143\n",
      "\n",
      "    accuracy                           0.49       243\n",
      "   macro avg       0.54      0.53      0.47       243\n",
      "weighted avg       0.56      0.49      0.46       243\n",
      "\n"
     ]
    }
   ],
   "source": [
    "machine_id = \"00\"\r\n",
    "temp = (\r\n",
    "    audios_df\r\n",
    "    .query(\"machine_id == @machine_id and split == 1\")\r\n",
    ")  \r\n",
    "print(classification_report(temp[\"label\"], temp[\"label_pred\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 78  22]\n",
      " [103  40]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(temp[\"label\"], temp[\"label_pred\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC score: 0.5299\n"
     ]
    }
   ],
   "source": [
    "score = roc_auc_score(temp[\"label\"], temp[\"label_pred\"])\r\n",
    "print(f\"ROC-AUC score: {score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model is slightly better distinguishing sounds for this machine that tossing a coin. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Machine_id=02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.47      0.76      0.58       100\n",
      "           1       0.53      0.24      0.33       111\n",
      "\n",
      "    accuracy                           0.49       211\n",
      "   macro avg       0.50      0.50      0.46       211\n",
      "weighted avg       0.50      0.49      0.45       211\n",
      "\n"
     ]
    }
   ],
   "source": [
    "machine_id = \"02\"\r\n",
    "temp = (\r\n",
    "    audios_df\r\n",
    "    .query(\"machine_id == @machine_id and split == 1\")\r\n",
    ")  \r\n",
    "print(classification_report(temp[\"label\"], temp[\"label_pred\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[76 24]\n",
      " [84 27]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(temp[\"label\"], temp[\"label_pred\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC score: 0.5016\n"
     ]
    }
   ],
   "source": [
    "score = roc_auc_score(temp[\"label\"], temp[\"label_pred\"])\r\n",
    "print(f\"ROC-AUC score: {score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model is slightly better distinguishing sounds for this machine that tossing a coin. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Machine_id=04"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.81      0.63       100\n",
      "           1       0.55      0.23      0.32       100\n",
      "\n",
      "    accuracy                           0.52       200\n",
      "   macro avg       0.53      0.52      0.48       200\n",
      "weighted avg       0.53      0.52      0.48       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "machine_id = \"04\"\r\n",
    "temp = (\r\n",
    "    audios_df\r\n",
    "    .query(\"machine_id == @machine_id and split == 1\")\r\n",
    ")  \r\n",
    "print(classification_report(temp[\"label\"], temp[\"label_pred\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[81 19]\n",
      " [77 23]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(temp[\"label\"], temp[\"label_pred\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC score: 0.5200\n"
     ]
    }
   ],
   "source": [
    "score = roc_auc_score(temp[\"label\"], temp[\"label_pred\"])\r\n",
    "print(f\"ROC-AUC score: {score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model is slightly better distinguishing sounds for this machine that tossing a coin. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Machine_id=06"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.47      0.74      0.58       100\n",
      "           1       0.42      0.19      0.26       102\n",
      "\n",
      "    accuracy                           0.46       202\n",
      "   macro avg       0.45      0.46      0.42       202\n",
      "weighted avg       0.45      0.46      0.42       202\n",
      "\n"
     ]
    }
   ],
   "source": [
    "machine_id = \"06\"\r\n",
    "temp = (\r\n",
    "    audios_df\r\n",
    "    .query(\"machine_id == @machine_id and split == 1\")\r\n",
    ")  \r\n",
    "print(classification_report(temp[\"label\"], temp[\"label_pred\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[74 26]\n",
      " [83 19]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(temp[\"label\"], temp[\"label_pred\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC score: 0.4631\n"
     ]
    }
   ],
   "source": [
    "score = roc_auc_score(temp[\"label\"], temp[\"label_pred\"])\r\n",
    "print(f\"ROC-AUC score: {score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model is so bad distinguishing sounds for this machine that tossing a coin can predict better. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although we tried to copy the baseline model for the DCASE 2020 challenge, metrics are worse."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "57fde4dc6cdb19e1d76ed7331772e4cf7a15b1a70b768f05e2959c60594bd89b"
  },
  "kernelspec": {
   "display_name": "Python 3.7.10 64-bit ('tfm': conda)",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": ""
  },
  "metadata": {
   "interpreter": {
    "hash": "57fde4dc6cdb19e1d76ed7331772e4cf7a15b1a70b768f05e2959c60594bd89b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}