{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Semi-supervised anomaly detection: log mel-spectrogram - model 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook will show how to implement in Tensorflow the AE model used as baseline for [DCASE 2020](http://dcase.community/challenge2020/task-unsupervised-detection-of-anomalous-sounds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load the libraries for this notebook.\n",
    "- **Tensorflow dataset** to load the dataset\n",
    "- **Tensorflow** to create an AE model\n",
    "- **Pandas** to manipulate results\n",
    "- **Sklearn** to compute metrics\n",
    "- **Plotnine** to plot results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.layers import (\n",
    "    InputLayer,\n",
    "    Dense,\n",
    "    BatchNormalization,\n",
    "    Activation,\n",
    ")\n",
    "\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import MeanSquaredError\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import sklearn\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix, \n",
    "    classification_report,\n",
    "    roc_auc_score\n",
    ")\n",
    "\n",
    "import plotnine as p9\n",
    "\n",
    "import datetime\n",
    "\n",
    "import os\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow datasets: 4.2.0\n",
      "Tensorflow: 2.4.1\n",
      "Sklearn: 0.24.2\n",
      "Numpy: 1.19.5\n",
      "Pandas: 1.2.4\n",
      "Plotnine: 0.8.0\n"
     ]
    }
   ],
   "source": [
    "print(f\"Tensorflow datasets: {tfds.__version__}\")\n",
    "print(f\"Tensorflow: {tf.__version__}\")\n",
    "print(f\"Sklearn: {sklearn.__version__}\")\n",
    "print(f\"Numpy: {np.__version__}\")\n",
    "print(f\"Pandas: {pd.__version__}\")\n",
    "print(f\"Plotnine: {p9.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's set the seed for the Tensorflow dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = tfds.ReadConfig(try_autocache=True, shuffle_seed=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load the dataset and create three sets (train, validation, test). We make the train set (90%) and validation set (10%) from the train data and the test set from the test data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pump\n",
    "data_dir = \"../dataset\"\n",
    "\n",
    "(train, val, test), info = tfds.load(\n",
    "    \"pump\",\n",
    "    split=[\"train[:90%]\", \"train[90%:]\", \"test\"],\n",
    "    data_dir=data_dir,\n",
    "    with_info=True,\n",
    "    shuffle_files=True,\n",
    "    read_config=config,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use 128 log mel-band energies from a spectrogram with an analysis frame of 64 ms and 50% hop size. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = tf.signal.linear_to_mel_weight_matrix(\n",
    "    num_mel_bins=128, num_spectrogram_bins=512+1, sample_rate=16_000, dtype=tf.float32\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mel(item):\n",
    "    audio = tf.cast(item[\"audio\"], tf.float32)\n",
    "    audio = audio / 2**15\n",
    "\n",
    "    # Calculate the STFT of the audio signal\n",
    "    stfts = tf.signal.stft(\n",
    "            audio,\n",
    "            frame_length=1024,\n",
    "            frame_step=512,\n",
    "            pad_end=False,  # librosa test compatibility\n",
    "        )\n",
    "    # Get Magnitude fo the STFT\n",
    "    mag_stfts = tf.abs(stfts)\n",
    "\n",
    "    # Get the mel-spectrogram\n",
    "    melgrams = tf.tensordot(\n",
    "            tf.square(mag_stfts), A, axes=1\n",
    "    )\n",
    "\n",
    "    # Change of base for logarithmics: from natural logarithmic to common logarithmic \n",
    "    def _tf_log10(x):\n",
    "        numerator = tf.math.log(x)\n",
    "        denominator = tf.math.log(tf.constant(10, dtype=numerator.dtype))\n",
    "        return numerator / denominator\n",
    "\n",
    "    # Calculate the log-mel spectrogram    \n",
    "    log_melgrams = 20 / 2 * _tf_log10(melgrams + 10e-6)\n",
    "\n",
    "    # Concat 5 time frames together to feed the model\n",
    "    concat_melgrams = tf.concat(\n",
    "        [\n",
    "            tf.roll(log_melgrams, shift=1, axis=0),\n",
    "            tf.roll(log_melgrams, shift=2, axis=0),\n",
    "            log_melgrams,\n",
    "            tf.roll(log_melgrams, shift=-1, axis=0),\n",
    "            tf.roll(log_melgrams, shift=-2, axis=0)\n",
    "        ],\n",
    "        axis=1,\n",
    "    )\n",
    "    concat_melgrams = concat_melgrams[2:-2,:]\n",
    "\n",
    "    item[\"audio\"] = concat_melgrams\n",
    "    return item"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's prepare the sets for training. AE models need that the input and the output be the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_train(item):\n",
    "    return item[\"audio\"], item[\"audio\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 512\n",
    "SHUFFLE_BUFFER_SIZE = 1024\n",
    "\n",
    "train = train.map(mel)\n",
    "train2 = train.map(prep_train).batch(BATCH_SIZE)\n",
    "\n",
    "val = train.map(mel)\n",
    "val2 = train.map(prep_train).batch(BATCH_SIZE)\n",
    "\n",
    "test = test.map(mel)\n",
    "test2 = test.batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the same AE model described used as baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder = Sequential(\n",
    "    [\n",
    "        InputLayer(input_shape=(307, 640)),\n",
    "        Dense(128),\n",
    "        BatchNormalization(),\n",
    "        Activation('relu'),\n",
    "        Dense(128),\n",
    "        BatchNormalization(),\n",
    "        Activation('relu'),\n",
    "        Dense(128),\n",
    "        BatchNormalization(),\n",
    "        Activation('relu'),\n",
    "        Dense(128),\n",
    "        BatchNormalization(),\n",
    "        Activation('relu'),\n",
    "        Dense(8),\n",
    "        BatchNormalization(),\n",
    "        Activation('relu'),\n",
    "        Dense(128),\n",
    "        BatchNormalization(),\n",
    "        Activation('relu'),\n",
    "        Dense(128),\n",
    "        BatchNormalization(),\n",
    "        Activation('relu'),\n",
    "        Dense(128),\n",
    "        BatchNormalization(),\n",
    "        Activation('relu'),\n",
    "        Dense(128),\n",
    "        BatchNormalization(),\n",
    "        Activation('relu'),\n",
    "        Dense(640)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 307, 128)          82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 307, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 307, 128)          0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 307, 128)          16512     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 307, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 307, 128)          0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 307, 128)          16512     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 307, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 307, 128)          0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 307, 128)          16512     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 307, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 307, 128)          0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 307, 8)            1032      \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 307, 8)            32        \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 307, 8)            0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 307, 128)          1152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 307, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 307, 128)          0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 307, 128)          16512     \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 307, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 307, 128)          0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 307, 128)          16512     \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 307, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 307, 128)          0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 307, 128)          16512     \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 307, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 307, 128)          0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 307, 640)          82560     \n",
      "=================================================================\n",
      "Total params: 269,992\n",
      "Trainable params: 267,928\n",
      "Non-trainable params: 2,064\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use same parameters as the paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.compile(optimizer=Adam(learning_rate=0.001), loss=MeanSquaredError())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a Tensorboard callback to check the results in Tensorboard and a ModelCheckpoint callback to save the best model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = os.path.join('..', 'logs', 'semi-mel', datetime.datetime.now().strftime('%Y%m%d-%H%M%S'))\n",
    "tb_callback = tf.keras.callbacks.TensorBoard(\n",
    "    log_dir, update_freq=1, histogram_freq=1, write_graph=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_filepath = os.path.join(\"tmp\", \"semi-mel\", \"checkpoint\")\n",
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    save_weights_only=True,\n",
    "    monitor='val_loss',\n",
    "    mode='min',\n",
    "    save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "6/6 [==============================] - 71s 12s/step - loss: 222.1035 - val_loss: 221.2142\n",
      "Epoch 2/100\n",
      "6/6 [==============================] - 68s 12s/step - loss: 213.8695 - val_loss: 214.2472\n",
      "Epoch 3/100\n",
      "6/6 [==============================] - 68s 12s/step - loss: 202.8994 - val_loss: 191.2484\n",
      "Epoch 4/100\n",
      "6/6 [==============================] - 68s 12s/step - loss: 191.1925 - val_loss: 166.1971\n",
      "Epoch 5/100\n",
      "6/6 [==============================] - 67s 12s/step - loss: 179.9613 - val_loss: 139.8357\n",
      "Epoch 6/100\n",
      "6/6 [==============================] - 67s 12s/step - loss: 167.8799 - val_loss: 124.0937\n",
      "Epoch 7/100\n",
      "6/6 [==============================] - 65s 11s/step - loss: 158.7889 - val_loss: 107.5820\n",
      "Epoch 8/100\n",
      "6/6 [==============================] - 66s 11s/step - loss: 148.2392 - val_loss: 95.0089\n",
      "Epoch 9/100\n",
      "6/6 [==============================] - 65s 11s/step - loss: 136.8130 - val_loss: 102.2799\n",
      "Epoch 10/100\n",
      "6/6 [==============================] - 66s 11s/step - loss: 127.6617 - val_loss: 107.9968\n",
      "Epoch 11/100\n",
      "6/6 [==============================] - 66s 11s/step - loss: 118.5323 - val_loss: 96.4742\n",
      "Epoch 12/100\n",
      "6/6 [==============================] - 66s 11s/step - loss: 110.1323 - val_loss: 93.3543\n",
      "Epoch 13/100\n",
      "6/6 [==============================] - 66s 11s/step - loss: 101.3055 - val_loss: 82.2488\n",
      "Epoch 14/100\n",
      "6/6 [==============================] - 66s 11s/step - loss: 93.1751 - val_loss: 90.1386\n",
      "Epoch 15/100\n",
      "6/6 [==============================] - 66s 11s/step - loss: 85.4615 - val_loss: 81.1834\n",
      "Epoch 16/100\n",
      "6/6 [==============================] - 66s 11s/step - loss: 78.5437 - val_loss: 82.3579\n",
      "Epoch 17/100\n",
      "6/6 [==============================] - 66s 12s/step - loss: 72.6503 - val_loss: 72.8478\n",
      "Epoch 18/100\n",
      "6/6 [==============================] - 66s 11s/step - loss: 66.6024 - val_loss: 65.1802\n",
      "Epoch 19/100\n",
      "6/6 [==============================] - 68s 12s/step - loss: 60.8543 - val_loss: 61.2912\n",
      "Epoch 20/100\n",
      "6/6 [==============================] - 67s 12s/step - loss: 56.0160 - val_loss: 54.8585\n",
      "Epoch 21/100\n",
      "6/6 [==============================] - 68s 12s/step - loss: 51.8923 - val_loss: 53.7966\n",
      "Epoch 22/100\n",
      "6/6 [==============================] - 68s 12s/step - loss: 47.6421 - val_loss: 46.5541\n",
      "Epoch 23/100\n",
      "6/6 [==============================] - 68s 12s/step - loss: 43.8203 - val_loss: 45.3750\n",
      "Epoch 24/100\n",
      "6/6 [==============================] - 67s 12s/step - loss: 40.4733 - val_loss: 42.9104\n",
      "Epoch 25/100\n",
      "6/6 [==============================] - 67s 12s/step - loss: 37.7748 - val_loss: 36.2077\n",
      "Epoch 26/100\n",
      "6/6 [==============================] - 66s 11s/step - loss: 35.2286 - val_loss: 37.8998\n",
      "Epoch 27/100\n",
      "6/6 [==============================] - 69s 12s/step - loss: 32.8795 - val_loss: 34.7197\n",
      "Epoch 28/100\n",
      "6/6 [==============================] - 70s 12s/step - loss: 31.3775 - val_loss: 35.0688\n",
      "Epoch 29/100\n",
      "6/6 [==============================] - 69s 12s/step - loss: 29.8090 - val_loss: 33.6410\n",
      "Epoch 30/100\n",
      "6/6 [==============================] - 70s 12s/step - loss: 28.3801 - val_loss: 28.8290\n",
      "Epoch 31/100\n",
      "6/6 [==============================] - 69s 12s/step - loss: 27.2803 - val_loss: 29.1413\n",
      "Epoch 32/100\n",
      "6/6 [==============================] - 69s 12s/step - loss: 26.2702 - val_loss: 28.4860\n",
      "Epoch 33/100\n",
      "6/6 [==============================] - 70s 12s/step - loss: 25.4860 - val_loss: 26.9985\n",
      "Epoch 34/100\n",
      "6/6 [==============================] - 68s 12s/step - loss: 24.9532 - val_loss: 27.0601\n",
      "Epoch 35/100\n",
      "6/6 [==============================] - 67s 12s/step - loss: 24.2372 - val_loss: 25.4018\n",
      "Epoch 36/100\n",
      "6/6 [==============================] - 67s 12s/step - loss: 23.7688 - val_loss: 25.6490\n",
      "Epoch 37/100\n",
      "6/6 [==============================] - 67s 12s/step - loss: 23.4370 - val_loss: 25.4442\n",
      "Epoch 38/100\n",
      "6/6 [==============================] - 67s 12s/step - loss: 23.0540 - val_loss: 24.3150\n",
      "Epoch 39/100\n",
      "6/6 [==============================] - 70s 12s/step - loss: 22.6747 - val_loss: 24.9680\n",
      "Epoch 40/100\n",
      "6/6 [==============================] - 70s 12s/step - loss: 22.5239 - val_loss: 23.6770\n",
      "Epoch 41/100\n",
      "6/6 [==============================] - 67s 12s/step - loss: 22.3922 - val_loss: 23.9861\n",
      "Epoch 42/100\n",
      "6/6 [==============================] - 69s 12s/step - loss: 22.2116 - val_loss: 24.0812\n",
      "Epoch 43/100\n",
      "6/6 [==============================] - 67s 12s/step - loss: 22.0958 - val_loss: 23.5230\n",
      "Epoch 44/100\n",
      "6/6 [==============================] - 69s 12s/step - loss: 21.9471 - val_loss: 23.4250\n",
      "Epoch 45/100\n",
      "6/6 [==============================] - 68s 12s/step - loss: 21.8124 - val_loss: 23.3695\n",
      "Epoch 46/100\n",
      "6/6 [==============================] - 68s 12s/step - loss: 21.9676 - val_loss: 23.6907\n",
      "Epoch 47/100\n",
      "6/6 [==============================] - 63s 11s/step - loss: 21.6392 - val_loss: 23.4227\n",
      "Epoch 48/100\n",
      "6/6 [==============================] - 60s 10s/step - loss: 21.6950 - val_loss: 23.5163\n",
      "Epoch 49/100\n",
      "6/6 [==============================] - 63s 11s/step - loss: 21.6054 - val_loss: 23.8040\n",
      "Epoch 50/100\n",
      "6/6 [==============================] - 54s 9s/step - loss: 21.5708 - val_loss: 23.4897\n",
      "Epoch 51/100\n",
      "6/6 [==============================] - 64s 11s/step - loss: 21.3713 - val_loss: 23.5600\n",
      "Epoch 52/100\n",
      "6/6 [==============================] - 58s 10s/step - loss: 21.4399 - val_loss: 23.8115\n",
      "Epoch 53/100\n",
      "6/6 [==============================] - 55s 9s/step - loss: 21.3154 - val_loss: 24.0024\n",
      "Epoch 54/100\n",
      "6/6 [==============================] - 54s 9s/step - loss: 21.2395 - val_loss: 24.3449\n",
      "Epoch 55/100\n",
      "6/6 [==============================] - 55s 9s/step - loss: 21.0514 - val_loss: 24.2029\n",
      "Epoch 56/100\n",
      "6/6 [==============================] - 63s 11s/step - loss: 21.1190 - val_loss: 24.2572\n",
      "Epoch 57/100\n",
      "6/6 [==============================] - 57s 10s/step - loss: 21.0694 - val_loss: 24.0079\n",
      "Epoch 58/100\n",
      "6/6 [==============================] - 56s 10s/step - loss: 21.0239 - val_loss: 23.8136\n",
      "Epoch 59/100\n",
      "6/6 [==============================] - 56s 10s/step - loss: 20.8863 - val_loss: 23.5592\n",
      "Epoch 60/100\n",
      "6/6 [==============================] - 56s 10s/step - loss: 20.9188 - val_loss: 23.0443\n",
      "Epoch 61/100\n",
      "6/6 [==============================] - 56s 10s/step - loss: 20.8734 - val_loss: 23.3135\n",
      "Epoch 62/100\n",
      "6/6 [==============================] - 55s 10s/step - loss: 20.6579 - val_loss: 23.6092\n",
      "Epoch 63/100\n",
      "6/6 [==============================] - 55s 9s/step - loss: 20.6804 - val_loss: 23.5965\n",
      "Epoch 64/100\n",
      "6/6 [==============================] - 56s 10s/step - loss: 20.7193 - val_loss: 23.4486\n",
      "Epoch 65/100\n",
      "6/6 [==============================] - 56s 10s/step - loss: 20.5326 - val_loss: 23.6779\n",
      "Epoch 66/100\n",
      "6/6 [==============================] - 56s 10s/step - loss: 20.5205 - val_loss: 23.4875\n",
      "Epoch 67/100\n",
      "6/6 [==============================] - 59s 10s/step - loss: 20.4129 - val_loss: 23.3379\n",
      "Epoch 68/100\n",
      "6/6 [==============================] - 57s 10s/step - loss: 20.4149 - val_loss: 23.1148\n",
      "Epoch 69/100\n",
      "6/6 [==============================] - 56s 10s/step - loss: 20.3453 - val_loss: 23.1678\n",
      "Epoch 70/100\n",
      "6/6 [==============================] - 57s 10s/step - loss: 20.3911 - val_loss: 22.8421\n",
      "Epoch 71/100\n",
      "6/6 [==============================] - 59s 10s/step - loss: 20.4451 - val_loss: 22.7239\n",
      "Epoch 72/100\n",
      "6/6 [==============================] - 62s 11s/step - loss: 20.3709 - val_loss: 22.6182\n",
      "Epoch 73/100\n",
      "6/6 [==============================] - 62s 11s/step - loss: 20.3314 - val_loss: 22.5058\n",
      "Epoch 74/100\n",
      "6/6 [==============================] - 59s 10s/step - loss: 20.1671 - val_loss: 22.3981\n",
      "Epoch 75/100\n",
      "6/6 [==============================] - 55s 9s/step - loss: 20.2344 - val_loss: 22.3663\n",
      "Epoch 76/100\n",
      "6/6 [==============================] - 54s 9s/step - loss: 20.1386 - val_loss: 22.3231\n",
      "Epoch 77/100\n",
      "6/6 [==============================] - 54s 9s/step - loss: 20.1435 - val_loss: 22.1647\n",
      "Epoch 78/100\n",
      "6/6 [==============================] - 54s 9s/step - loss: 20.0644 - val_loss: 22.0778\n",
      "Epoch 79/100\n",
      "6/6 [==============================] - 54s 9s/step - loss: 20.0460 - val_loss: 22.1434\n",
      "Epoch 80/100\n",
      "6/6 [==============================] - 56s 10s/step - loss: 20.0725 - val_loss: 22.1088\n",
      "Epoch 81/100\n",
      "6/6 [==============================] - 55s 9s/step - loss: 20.0626 - val_loss: 21.8455\n",
      "Epoch 82/100\n",
      "6/6 [==============================] - 55s 9s/step - loss: 19.9861 - val_loss: 21.8471\n",
      "Epoch 83/100\n",
      "6/6 [==============================] - 55s 9s/step - loss: 19.9011 - val_loss: 21.8188\n",
      "Epoch 84/100\n",
      "6/6 [==============================] - 56s 10s/step - loss: 19.9050 - val_loss: 21.7270\n",
      "Epoch 85/100\n",
      "6/6 [==============================] - 56s 10s/step - loss: 19.9152 - val_loss: 21.7796\n",
      "Epoch 86/100\n",
      "6/6 [==============================] - 54s 9s/step - loss: 19.7895 - val_loss: 21.6521\n",
      "Epoch 87/100\n",
      "6/6 [==============================] - 50s 9s/step - loss: 19.8270 - val_loss: 21.6769\n",
      "Epoch 88/100\n",
      "6/6 [==============================] - 50s 9s/step - loss: 19.7717 - val_loss: 21.5963\n",
      "Epoch 89/100\n",
      "6/6 [==============================] - 49s 9s/step - loss: 19.7440 - val_loss: 21.4725\n",
      "Epoch 90/100\n",
      "6/6 [==============================] - 50s 9s/step - loss: 19.7336 - val_loss: 21.4696\n",
      "Epoch 91/100\n",
      "6/6 [==============================] - 50s 9s/step - loss: 19.6599 - val_loss: 21.4828\n",
      "Epoch 92/100\n",
      "6/6 [==============================] - 51s 9s/step - loss: 19.6647 - val_loss: 21.4171\n",
      "Epoch 93/100\n",
      "6/6 [==============================] - 49s 9s/step - loss: 19.5394 - val_loss: 21.3514\n",
      "Epoch 94/100\n",
      "6/6 [==============================] - 49s 9s/step - loss: 19.5707 - val_loss: 21.2782\n",
      "Epoch 95/100\n",
      "6/6 [==============================] - 51s 9s/step - loss: 19.6070 - val_loss: 21.1413\n",
      "Epoch 96/100\n",
      "6/6 [==============================] - 49s 8s/step - loss: 19.4508 - val_loss: 21.2843\n",
      "Epoch 97/100\n",
      "6/6 [==============================] - 50s 9s/step - loss: 19.4551 - val_loss: 21.1884\n",
      "Epoch 98/100\n",
      "6/6 [==============================] - 50s 9s/step - loss: 19.5167 - val_loss: 20.7586\n",
      "Epoch 99/100\n",
      "6/6 [==============================] - 51s 9s/step - loss: 19.4455 - val_loss: 20.8249\n",
      "Epoch 100/100\n",
      "6/6 [==============================] - 55s 10s/step - loss: 19.3618 - val_loss: 20.8794\n"
     ]
    }
   ],
   "source": [
    "history = autoencoder.fit(\n",
    "    train2,\n",
    "    epochs=100,\n",
    "    shuffle=True,\n",
    "    validation_data=val2,\n",
    "    callbacks=[tb_callback, model_checkpoint_callback],\n",
    "    verbose=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x1c4b6324d08>"
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autoencoder.load_weights(checkpoint_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ..\\..\\..\\production\\backend\\models\\mel\\1\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ..\\..\\..\\production\\backend\\models\\mel\\1\\assets\n"
     ]
    }
   ],
   "source": [
    "VERSION=\"1\"\r\n",
    "saved_model_path = autoencoder.save(\r\n",
    "    os.path.join(\"..\", \"..\", \"..\", \"production\", \"backend\", \"models\", \"mel\", VERSION),\r\n",
    "    save_format=\"tf\",\r\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's join train and test set together for faster predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "audios = train.concatenate(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = autoencoder.predict(audios.map(lambda item: item[\"audio\"]).batch(BATCH_SIZE))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's compute the reconstruction error for all audios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_lst = []\n",
    "for item, pred in zip(tfds.as_numpy(audios), pred):\n",
    "    error = np.mean(np.square(item[\"audio\"] - pred))\n",
    "    error_lst.append(error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To check how the model behaves, we can tranform the Tensorflow dataset into a dataframe and add the previous computed reconstruction error to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>audio</th>\n      <th>id</th>\n      <th>machine_id</th>\n      <th>split</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1307</th>\n      <td>[[-9.874631, -6.8349433, -2.0404174, -4.321853...</td>\n      <td>0164</td>\n      <td>04</td>\n      <td>train</td>\n      <td>normal</td>\n    </tr>\n    <tr>\n      <th>1663</th>\n      <td>[[-12.179075, -7.697941, -2.2378461, -6.618811...</td>\n      <td>0062</td>\n      <td>04</td>\n      <td>train</td>\n      <td>normal</td>\n    </tr>\n    <tr>\n      <th>3847</th>\n      <td>[[2.2923799, 1.3340228, -3.297722, -6.108287, ...</td>\n      <td>0007</td>\n      <td>04</td>\n      <td>test</td>\n      <td>anomaly</td>\n    </tr>\n    <tr>\n      <th>2092</th>\n      <td>[[-4.48533, -5.019704, -6.227432, -39.863815, ...</td>\n      <td>0018</td>\n      <td>04</td>\n      <td>train</td>\n      <td>normal</td>\n    </tr>\n    <tr>\n      <th>1534</th>\n      <td>[[-8.116749, -9.269882, -17.792938, -11.89989,...</td>\n      <td>0299</td>\n      <td>00</td>\n      <td>train</td>\n      <td>normal</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "                                                  audio    id machine_id  \\\n1307  [[-9.874631, -6.8349433, -2.0404174, -4.321853...  0164         04   \n1663  [[-12.179075, -7.697941, -2.2378461, -6.618811...  0062         04   \n3847  [[2.2923799, 1.3340228, -3.297722, -6.108287, ...  0007         04   \n2092  [[-4.48533, -5.019704, -6.227432, -39.863815, ...  0018         04   \n1534  [[-8.116749, -9.269882, -17.792938, -11.89989,...  0299         00   \n\n      split    label  \n1307  train   normal  \n1663  train   normal  \n3847   test  anomaly  \n2092  train   normal  \n1534  train   normal  "
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audios_df = tfds.as_dataframe(audios, info)\n",
    "\n",
    "# Convert byte-type texts to string-type texts\n",
    "for col in audios_df:\n",
    "    if isinstance(audios_df[col][0], bytes):\n",
    "        audios_df[col] = audios_df[col].str.decode(\"utf8\")\n",
    "\n",
    "dct_columns = {\n",
    "    \"audio/id\": \"id\", \n",
    "    \"audio/machine\": \"machine_id\", \n",
    "    \"audio/split\": \"split\",\n",
    "}\n",
    "\n",
    "# Convert object-type columns to a more convenient data type\n",
    "dct_types = {\n",
    "    \"id\": \"string\",\n",
    "    \"machine_id\": \"category\",\n",
    "    \"split\": \"category\",\n",
    "    \"label\": \"category\",\n",
    "}\n",
    "\n",
    "audios_df = (\n",
    "    audios_df\n",
    "    .rename(columns=dct_columns)\n",
    "    .astype(dct_types)\n",
    ")\n",
    "\n",
    "audios_df[\"split\"] = audios_df[\"split\"].cat.rename_categories({0: \"train\", 1: \"test\"})\n",
    "audios_df[\"label\"] = audios_df[\"label\"].cat.rename_categories({0: \"normal\", 1: \"anomaly\"})\n",
    "\n",
    "audios_df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "audios_df[\"error\"] = error_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>audio</th>\n      <th>id</th>\n      <th>machine_id</th>\n      <th>split</th>\n      <th>label</th>\n      <th>error</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2953</th>\n      <td>[[-3.1785088, -2.1869829, 0.71435684, -0.11960...</td>\n      <td>0496</td>\n      <td>06</td>\n      <td>train</td>\n      <td>normal</td>\n      <td>32.028820</td>\n    </tr>\n    <tr>\n      <th>1076</th>\n      <td>[[-2.4113069, -3.2431123, -6.5061135, -8.96151...</td>\n      <td>0472</td>\n      <td>00</td>\n      <td>train</td>\n      <td>normal</td>\n      <td>35.711353</td>\n    </tr>\n    <tr>\n      <th>2085</th>\n      <td>[[-9.033941, -2.5568657, 3.4455492, 3.7080374,...</td>\n      <td>0263</td>\n      <td>04</td>\n      <td>train</td>\n      <td>normal</td>\n      <td>51.452026</td>\n    </tr>\n    <tr>\n      <th>2523</th>\n      <td>[[-12.292691, -12.874882, -14.346399, -7.57007...</td>\n      <td>0583</td>\n      <td>04</td>\n      <td>train</td>\n      <td>normal</td>\n      <td>38.696583</td>\n    </tr>\n    <tr>\n      <th>1948</th>\n      <td>[[-0.7825079, -1.3064833, -2.4592886, -8.19665...</td>\n      <td>0684</td>\n      <td>02</td>\n      <td>train</td>\n      <td>normal</td>\n      <td>21.521887</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "                                                  audio    id machine_id  \\\n2953  [[-3.1785088, -2.1869829, 0.71435684, -0.11960...  0496         06   \n1076  [[-2.4113069, -3.2431123, -6.5061135, -8.96151...  0472         00   \n2085  [[-9.033941, -2.5568657, 3.4455492, 3.7080374,...  0263         04   \n2523  [[-12.292691, -12.874882, -14.346399, -7.57007...  0583         04   \n1948  [[-0.7825079, -1.3064833, -2.4592886, -8.19665...  0684         02   \n\n      split   label      error  \n2953  train  normal  32.028820  \n1076  train  normal  35.711353  \n2085  train  normal  51.452026  \n2523  train  normal  38.696583  \n1948  train  normal  21.521887  "
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audios_df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead tr th {\n        text-align: left;\n    }\n\n    .dataframe thead tr:last-of-type th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr>\n      <th></th>\n      <th colspan=\"2\" halign=\"left\">error</th>\n    </tr>\n    <tr>\n      <th></th>\n      <th>mean</th>\n      <th>std</th>\n    </tr>\n    <tr>\n      <th>machine_id</th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>00</th>\n      <td>33.149893</td>\n      <td>15.331841</td>\n    </tr>\n    <tr>\n      <th>02</th>\n      <td>32.553738</td>\n      <td>14.315009</td>\n    </tr>\n    <tr>\n      <th>04</th>\n      <td>32.871041</td>\n      <td>14.002614</td>\n    </tr>\n    <tr>\n      <th>06</th>\n      <td>34.219801</td>\n      <td>15.921031</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "                error           \n                 mean        std\nmachine_id                      \n00          33.149893  15.331841\n02          32.553738  14.315009\n04          32.871041  14.002614\n06          34.219801  15.921031"
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(\n",
    "    audios_df\n",
    "    .query(\"split == 'train'\")\n",
    "    .groupby(\"machine_id\")\n",
    "    .agg({\"error\": [\"mean\", \"std\"]})\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead tr th {\n        text-align: left;\n    }\n\n    .dataframe thead tr:last-of-type th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr>\n      <th></th>\n      <th></th>\n      <th colspan=\"2\" halign=\"left\">error</th>\n    </tr>\n    <tr>\n      <th></th>\n      <th></th>\n      <th>mean</th>\n      <th>std</th>\n    </tr>\n    <tr>\n      <th>label</th>\n      <th>machine_id</th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th rowspan=\"4\" valign=\"top\">normal</th>\n      <th>00</th>\n      <td>37.253017</td>\n      <td>22.156428</td>\n    </tr>\n    <tr>\n      <th>02</th>\n      <td>34.656466</td>\n      <td>15.223976</td>\n    </tr>\n    <tr>\n      <th>04</th>\n      <td>35.231260</td>\n      <td>17.636893</td>\n    </tr>\n    <tr>\n      <th>06</th>\n      <td>36.572568</td>\n      <td>16.185259</td>\n    </tr>\n    <tr>\n      <th rowspan=\"4\" valign=\"top\">anomaly</th>\n      <th>00</th>\n      <td>40.008845</td>\n      <td>20.102486</td>\n    </tr>\n    <tr>\n      <th>02</th>\n      <td>38.128644</td>\n      <td>20.785872</td>\n    </tr>\n    <tr>\n      <th>04</th>\n      <td>36.555383</td>\n      <td>17.779424</td>\n    </tr>\n    <tr>\n      <th>06</th>\n      <td>34.843085</td>\n      <td>15.920741</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "                        error           \n                         mean        std\nlabel   machine_id                      \nnormal  00          37.253017  22.156428\n        02          34.656466  15.223976\n        04          35.231260  17.636893\n        06          36.572568  16.185259\nanomaly 00          40.008845  20.102486\n        02          38.128644  20.785872\n        04          36.555383  17.779424\n        06          34.843085  15.920741"
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(\n",
    "    audios_df\n",
    "    .query(\"split == 'test'\")\n",
    "    .groupby([\"label\", \"machine_id\"])\n",
    "    .agg({\"error\": [\"mean\", \"std\"]})\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems this model can't distinguish anomaly sound from normal sounds very well.\n",
    "\n",
    "Let's plot the a histogram of the construction error per machine to see more clear."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": "<Figure size 640x480 with 4 Axes>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "p = (\n",
    "    p9.ggplot(audios_df.query(\"split == 'test'\"), p9.aes(x=\"error\", fill=\"label\"))\n",
    "    + p9.geom_histogram(\n",
    "        p9.aes(y=\"stat(count)\"), position=\"identity\", alpha=0.75\n",
    "    )\n",
    "    + p9.scale_x_continuous(name=\"Testing reconstruction error\")\n",
    "    + p9.scale_y_continuous(name=\"Number samples\")\n",
    "    + p9.labs(\n",
    "        title=\"Reconstruction error distributions\",\n",
    "    )\n",
    "    + p9.scale_fill_brewer(type=\"qualitative\", palette=\"Accent\") \n",
    "    + p9.facet_grid(\"machine_id ~ .\", scales=\"free\")\n",
    "    + p9.theme_bw()\n",
    "    + p9.theme(\n",
    "        panel_border=p9.element_rect(colour=\"black\", fill=None, size=0.5),\n",
    "        axis_text_x=p9.element_text(colour=\"black\", size=9),\n",
    "        axis_text_y=p9.element_text(colour=\"black\", size=9),\n",
    "        legend_key=p9.element_blank(),\n",
    "        legend_title=p9.element_blank(),\n",
    "        panel_grid_major=p9.element_line(colour=\"#d3d3d3\"),\n",
    "        panel_grid_minor=p9.element_blank(),\n",
    "        panel_background=p9.element_blank(),\n",
    "        plot_title=p9.element_text(size=14, family=\"Tahoma\", face=\"bold\"),\n",
    "        text=p9.element_text(family=\"Tahoma\"),\n",
    "    )\n",
    ")\n",
    "\n",
    "print(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Histograms show more clear that the model can't differentiate anomaly audios from normal audio very well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This [AWS](https://aws.amazon.com/es/blogs/machine-learning/performing-anomaly-detection-on-industrial-equipment-using-audio-signals/) post shows how the histogram from a good model should look like.\n",
    "\n",
    "![Better model](https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2020/12/22/ML-1479-4.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how bad our model is. To distinguish anomaly audios from normal audios, we set the threshold one standard deviation above the mean of the train set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg = (\n",
    "    audios_df\n",
    "    .query(\"split == 'train'\")\n",
    "    [\"error\"]\n",
    "    .mean()\n",
    ")\n",
    "\n",
    "std = (\n",
    "    audios_df\n",
    "    .query(\"split == 'train'\")\n",
    "    [\"error\"]\n",
    "    .std()\n",
    ")\n",
    "\n",
    "threshold = avg + std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a new column with the predicted label based on the threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48.243759038053106\n"
     ]
    }
   ],
   "source": [
    "print(threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>audio</th>\n      <th>id</th>\n      <th>machine_id</th>\n      <th>split</th>\n      <th>label</th>\n      <th>error</th>\n      <th>label_pred</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>[[1.5932982, 1.294384, 1.1611198, -24.297667, ...</td>\n      <td>0784</td>\n      <td>06</td>\n      <td>train</td>\n      <td>normal</td>\n      <td>19.163870</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>[[-7.030608, -7.263412, -7.1459956, -13.880009...</td>\n      <td>0215</td>\n      <td>02</td>\n      <td>train</td>\n      <td>normal</td>\n      <td>26.678539</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>[[-7.4239073, -7.0891733, -5.364052, -14.60322...</td>\n      <td>0918</td>\n      <td>06</td>\n      <td>train</td>\n      <td>normal</td>\n      <td>20.216681</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>[[-5.473754, -4.7174063, -2.182263, -6.692034,...</td>\n      <td>0033</td>\n      <td>06</td>\n      <td>train</td>\n      <td>normal</td>\n      <td>26.082094</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>[[-32.570705, -10.010296, -3.2296658, -0.16753...</td>\n      <td>0580</td>\n      <td>02</td>\n      <td>train</td>\n      <td>normal</td>\n      <td>29.236591</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "                                               audio    id machine_id  split  \\\n0  [[1.5932982, 1.294384, 1.1611198, -24.297667, ...  0784         06  train   \n1  [[-7.030608, -7.263412, -7.1459956, -13.880009...  0215         02  train   \n2  [[-7.4239073, -7.0891733, -5.364052, -14.60322...  0918         06  train   \n3  [[-5.473754, -4.7174063, -2.182263, -6.692034,...  0033         06  train   \n4  [[-32.570705, -10.010296, -3.2296658, -0.16753...  0580         02  train   \n\n    label      error  label_pred  \n0  normal  19.163870           0  \n1  normal  26.678539           0  \n2  normal  20.216681           0  \n3  normal  26.082094           0  \n4  normal  29.236591           0  "
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audios_df[\"label_pred\"] = audios_df[\"error\"] > threshold\n",
    "\n",
    "audios_df = audios_df.astype({\"label_pred\": \"int\"})\n",
    "audios_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's show the precision, recall, f1-score and roc-auc score for the four machines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "audios_df[\"label\"] = audios_df[\"label\"].cat.rename_categories({\"normal\": 0, \"anomaly\": 1})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Machine_id=00"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.42      0.79      0.55       100\n",
      "           1       0.63      0.25      0.36       143\n",
      "\n",
      "    accuracy                           0.47       243\n",
      "   macro avg       0.53      0.52      0.46       243\n",
      "weighted avg       0.55      0.47      0.44       243\n",
      "\n"
     ]
    }
   ],
   "source": [
    "machine_id = \"00\"\n",
    "temp = (\n",
    "    audios_df\n",
    "    .query(\"machine_id == @machine_id and split == 'test'\")\n",
    ")  \n",
    "print(classification_report(temp[\"label\"], temp[\"label_pred\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 79  21]\n",
      " [107  36]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(temp[\"label\"], temp[\"label_pred\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC score: 0.5209\n"
     ]
    }
   ],
   "source": [
    "score = roc_auc_score(temp[\"label\"], temp[\"label_pred\"])\n",
    "print(f\"ROC-AUC score: {score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model is slightly better distinguishing sounds for this machine that tossing a coin. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Machine_id=02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.81      0.60       100\n",
      "           1       0.56      0.22      0.31       111\n",
      "\n",
      "    accuracy                           0.50       211\n",
      "   macro avg       0.52      0.51      0.46       211\n",
      "weighted avg       0.52      0.50      0.45       211\n",
      "\n"
     ]
    }
   ],
   "source": [
    "machine_id = \"02\"\n",
    "temp = (\n",
    "    audios_df\n",
    "    .query(\"machine_id == @machine_id and split == 'test'\")\n",
    ")  \n",
    "print(classification_report(temp[\"label\"], temp[\"label_pred\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[81 19]\n",
      " [87 24]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(temp[\"label\"], temp[\"label_pred\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC score: 0.5131\n"
     ]
    }
   ],
   "source": [
    "score = roc_auc_score(temp[\"label\"], temp[\"label_pred\"])\n",
    "print(f\"ROC-AUC score: {score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model is slightly better distinguishing sounds for this machine that tossing a coin. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Machine_id=04"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.83      0.63       100\n",
      "           1       0.54      0.20      0.29       100\n",
      "\n",
      "    accuracy                           0.52       200\n",
      "   macro avg       0.52      0.52      0.46       200\n",
      "weighted avg       0.52      0.52      0.46       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "machine_id = \"04\"\n",
    "temp = (\n",
    "    audios_df\n",
    "    .query(\"machine_id == @machine_id and split == 'test'\")\n",
    ")  \n",
    "print(classification_report(temp[\"label\"], temp[\"label_pred\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[83 17]\n",
      " [80 20]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(temp[\"label\"], temp[\"label_pred\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC score: 0.5150\n"
     ]
    }
   ],
   "source": [
    "score = roc_auc_score(temp[\"label\"], temp[\"label_pred\"])\n",
    "print(f\"ROC-AUC score: {score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model is slightly better distinguishing sounds for this machine that tossing a coin. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Machine_id=06"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.80      0.62       100\n",
      "           1       0.55      0.24      0.33       102\n",
      "\n",
      "    accuracy                           0.51       202\n",
      "   macro avg       0.53      0.52      0.47       202\n",
      "weighted avg       0.53      0.51      0.47       202\n",
      "\n"
     ]
    }
   ],
   "source": [
    "machine_id = \"06\"\n",
    "temp = (\n",
    "    audios_df\n",
    "    .query(\"machine_id == @machine_id and split == 'test'\")\n",
    ")  \n",
    "print(classification_report(temp[\"label\"], temp[\"label_pred\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[80 20]\n",
      " [78 24]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(temp[\"label\"], temp[\"label_pred\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC score: 0.5176\n"
     ]
    }
   ],
   "source": [
    "score = roc_auc_score(temp[\"label\"], temp[\"label_pred\"])\n",
    "print(f\"ROC-AUC score: {score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model is so bad distinguishing sounds for this machine that tossing a coin can predict better. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although we tried to copy the baseline model for the DCASE 2020 challenge, metrics are worse."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "57fde4dc6cdb19e1d76ed7331772e4cf7a15b1a70b768f05e2959c60594bd89b"
  },
  "kernelspec": {
   "display_name": "Python 3.7.10 64-bit ('tfm': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "metadata": {
   "interpreter": {
    "hash": "57fde4dc6cdb19e1d76ed7331772e4cf7a15b1a70b768f05e2959c60594bd89b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}