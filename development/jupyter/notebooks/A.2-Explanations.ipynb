{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explanations for differences between models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The metrics of my models are worse than the metrics of the models described in the paper [MIMII Dataset: Sound Dataset for\r\n",
    "Malfunctioning Industrial Machine Investigation and Inspection](https://www.arxiv-vanity.com/papers/1909.09347/) and in the [DCASE 2020](http://dcase.community/challenge2020/task-unsupervised-detection-of-anomalous-sounds) challenge.\r\n",
    "\r\n",
    "Let's find for some differences between models. We can check whether Tensorflow and Librosa computes melspectrogram the same way."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load the libraries for this notebook.\r\n",
    "- **Tensorflow dataset** to load the dataset\r\n",
    "- **Tensorflow** to compute the melspectrogram\r\n",
    "- **Librosa** to compute the melspectrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_datasets as tfds\r\n",
    "import tensorflow as tf\r\n",
    "import librosa\r\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print(f\"Tensorflow datasets: {tfds.__version__}\")\r\n",
    "print(f\"Tensorflow: {tf.__version__}\")\r\n",
    "print(f\"Librosa: {librosa.__version__})\r\n",
    "print(f\"Numpy: {np.__version__})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's compare how Tensorflow and Librosa load the files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load audio - Librosa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load an audio sample in Librosa and compare it to Tensorflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "y, sr = librosa.load(\"../audio/normal_id_00_00000001.wav\", sr=16_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "(160000,)"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "array([ 0.00753784,  0.00952148,  0.00723267, ...,  0.00387573,\n       -0.00448608, -0.00930786], dtype=float32)"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read audio - Tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load all audios from the train set and use the same file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pump\r\n",
    "\r\n",
    "ds, info = tfds.load('pump', data_dir='../dataset', with_info=True, split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y2 = ds.filter(lambda x: (x[\"audio/id\"] == \"0001\") & (x[\"audio/machine\"] == \"00\") & (x[\"label\"] == 0)).take(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While Librosa converts the audio file to [-1,1], Tensorflow keeps the audio as it is, so we need to convert the audio file manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_audio(item):\r\n",
    "    audio = tf.cast(item[\"audio\"], dtype=tf.float32)\r\n",
    "    return audio / 2**15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(160000,)\n"
     ]
    }
   ],
   "source": [
    "for item in tfds.as_numpy(y2.map(get_audio)):\r\n",
    "    print(item.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.00753784  0.00952148  0.00723267 ...  0.00387573 -0.00448608\n",
      " -0.00930786]\n"
     ]
    }
   ],
   "source": [
    "for item in tfds.as_numpy(y2.map(get_audio)):\r\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Melspectrogram - Librosa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Librosa has a function to compute melspectrogram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "mel = librosa.feature.melspectrogram(y, sr=sr, n_fft=1024, hop_length=512, win_length=1024)\r\n",
    "mel = mel.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(313, 128)\n"
     ]
    }
   ],
   "source": [
    "print(mel.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.00101106 0.00114903 0.01032275 ... 0.00013775 0.00030552 0.00011243]\n",
      " [0.00108913 0.05064675 0.07002663 ... 0.00029311 0.00026508 0.00019343]\n",
      " [0.00242773 0.01337171 0.04502779 ... 0.00035344 0.00019846 0.00027182]\n",
      " ...\n",
      " [0.00131706 0.01724362 0.02030062 ... 0.00034941 0.00044532 0.00034768]\n",
      " [0.00017864 0.00132901 0.00230213 ... 0.00020018 0.0005161  0.0001482 ]\n",
      " [0.00027024 0.0052782  0.01378242 ... 0.00060662 0.00054907 0.00031097]]\n"
     ]
    }
   ],
   "source": [
    "print(mel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Melspectrogram - Tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensorflow doesn't have a function to compute melspectrograms, so we need to compute it manually in two steps:\r\n",
    "- Compute the spectrogram\r\n",
    "- Transform the spectrogram to melspectrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = tf.signal.linear_to_mel_weight_matrix(\r\n",
    "    num_mel_bins=128, num_spectrogram_bins=512+1, sample_rate=16_000, dtype=tf.float32\r\n",
    ")\r\n",
    "\r\n",
    "def get_mel(item):\r\n",
    "    audio = tf.cast(item[\"audio\"], dtype=tf.float32)\r\n",
    "    audio = audio / 2**15\r\n",
    "    # Step 1: Spectrogram\r\n",
    "    audio = tf.signal.stft(audio, frame_length=1024, frame_step=512, pad_end=True)\r\n",
    "    audio = tf.abs(audio)\r\n",
    "\r\n",
    "    # Step 2: Mel-spectrogram\r\n",
    "    melgrams = tf.tensordot(\r\n",
    "            tf.square(audio), A, axes=1\r\n",
    "    )\r\n",
    "    item[\"audio\"] = melgrams\r\n",
    "\r\n",
    "    return item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(313, 128)\n"
     ]
    }
   ],
   "source": [
    "for item in tfds.as_numpy(y2.map(get_mel)):\r\n",
    "    print(item[\"audio\"].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.10853923 0.15231696 0.3422672  ... 0.11376878 0.0879589  0.11626314]\n",
      " [0.05918069 0.06871993 0.11805227 ... 0.02720353 0.04023996 0.11747861]\n",
      " [0.09808303 0.09334564 0.09733989 ... 0.13244948 0.14757505 0.12772648]\n",
      " ...\n",
      " [0.00873664 0.02683789 0.09729988 ... 0.11934654 0.05534454 0.05542446]\n",
      " [0.07337632 0.065545   0.05230678 ... 0.16141652 0.14283478 0.16025962]\n",
      " [0.00270342 0.00262386 0.00292703 ... 0.00168895 0.00881386 0.0111219 ]]\n"
     ]
    }
   ],
   "source": [
    "for item in tfds.as_numpy(y2.map(get_mel)):\r\n",
    "    print(item[\"audio\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Melspectrograms show big differences."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "57fde4dc6cdb19e1d76ed7331772e4cf7a15b1a70b768f05e2959c60594bd89b"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('tfm': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "metadata": {
   "interpreter": {
    "hash": "57fde4dc6cdb19e1d76ed7331772e4cf7a15b1a70b768f05e2959c60594bd89b"
   }
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}