{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explanations for differences between models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The metrics of my models are worse than the metrics of the models described in the paper [MIMII Dataset: Sound Dataset for\n",
    "Malfunctioning Industrial Machine Investigation and Inspection](https://www.arxiv-vanity.com/papers/1909.09347/) and in the [DCASE 2020](http://dcase.community/challenge2020/task-unsupervised-detection-of-anomalous-sounds) challenge.\n",
    "\n",
    "Let's find for some differences between models. We can check whether Tensorflow and Librosa computes melspectrogram the same way."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load the libraries for this notebook.\n",
    "- **Tensorflow dataset** to load the dataset\n",
    "- **Tensorflow** to compute the melspectrogram\n",
    "- **Librosa** to compute the melspectrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "import tensorflow as tf\n",
    "import librosa\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow datasets: 4.3.0\n",
      "Tensorflow: 2.4.1\n",
      "Librosa: 0.8.0\n",
      "Numpy: 1.19.5\n"
     ]
    }
   ],
   "source": [
    "print(f\"Tensorflow datasets: {tfds.__version__}\")\n",
    "print(f\"Tensorflow: {tf.__version__}\")\n",
    "print(f\"Librosa: {librosa.__version__}\")\n",
    "print(f\"Numpy: {np.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's compare how Tensorflow and Librosa load the files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load audio - Librosa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load an audio sample in Librosa and compare it to Tensorflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_path = os.path.join(\"..\", \"audio\", \"normal_id_00_00000001.wav\")\n",
    "y, sr = librosa.load(audio_path, sr=16_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(160000,)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.00753784,  0.00952148,  0.00723267, ...,  0.00387573,\n",
       "       -0.00448608, -0.00930786], dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read audio - Tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load all audios from the train set and use the same file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pump\n",
    "\n",
    "ds, info = tfds.load('pump', data_dir='../dataset', with_info=True, split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y2 = ds.filter(lambda x: (x[\"audio/id\"] == \"0001\") & (x[\"audio/machine\"] == \"00\") & (x[\"label\"] == 0)).take(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While Librosa converts the audio file to [-1,1], Tensorflow keeps the audio as it is, so we need to convert the audio file manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_audio(item):\n",
    "    audio = tf.cast(item[\"audio\"], dtype=tf.float32)\n",
    "    return audio / 2**15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(160000,)\n"
     ]
    }
   ],
   "source": [
    "for item in tfds.as_numpy(y2.map(get_audio)):\n",
    "    print(item.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.00753784  0.00952148  0.00723267 ...  0.00387573 -0.00448608\n",
      " -0.00930786]\n"
     ]
    }
   ],
   "source": [
    "for item in tfds.as_numpy(y2.map(get_audio)):\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Melspectrogram - Librosa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Librosa has a function to compute melspectrogram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "mel = librosa.feature.melspectrogram(y, sr=sr, n_fft=1024, hop_length=512, win_length=1024)\n",
    "mel = mel.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(313, 128)\n"
     ]
    }
   ],
   "source": [
    "print(mel.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.00101106 0.00114903 0.01032275 ... 0.00013775 0.00030552 0.00011243]\n",
      " [0.00108913 0.05064675 0.07002663 ... 0.00029311 0.00026508 0.00019343]\n",
      " [0.00242773 0.01337171 0.04502779 ... 0.00035344 0.00019846 0.00027182]\n",
      " ...\n",
      " [0.00131706 0.01724362 0.02030062 ... 0.00034941 0.00044532 0.00034768]\n",
      " [0.00017864 0.00132901 0.00230213 ... 0.00020018 0.0005161  0.0001482 ]\n",
      " [0.00027024 0.0052782  0.01378242 ... 0.00060662 0.00054907 0.00031097]]\n"
     ]
    }
   ],
   "source": [
    "print(mel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Melspectrogram - Tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensorflow doesn't have a function to compute melspectrograms, so we need to compute it manually in two steps:\n",
    "- Compute the spectrogram\n",
    "- Transform the spectrogram to melspectrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = tf.signal.linear_to_mel_weight_matrix(\n",
    "    num_mel_bins=128, num_spectrogram_bins=512+1, sample_rate=16_000, dtype=tf.float32\n",
    ")\n",
    "\n",
    "def get_mel(item):\n",
    "    audio = tf.cast(item[\"audio\"], dtype=tf.float32)\n",
    "    audio = audio / 2**15\n",
    "    # Step 1: Spectrogram\n",
    "    audio = tf.signal.stft(audio, frame_length=1024, frame_step=512, pad_end=True)\n",
    "    audio = tf.abs(audio)\n",
    "\n",
    "    # Step 2: Mel-spectrogram\n",
    "    melgrams = tf.tensordot(\n",
    "            tf.square(audio), A, axes=1\n",
    "    )\n",
    "    item[\"audio\"] = melgrams\n",
    "\n",
    "    return item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(313, 128)\n"
     ]
    }
   ],
   "source": [
    "for item in tfds.as_numpy(y2.map(get_mel)):\n",
    "    print(item[\"audio\"].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.10853923 0.15231696 0.3422672  ... 0.11376878 0.0879589  0.11626314]\n",
      " [0.05918069 0.06871993 0.11805227 ... 0.02720353 0.04023996 0.11747861]\n",
      " [0.09808303 0.09334564 0.09733989 ... 0.13244948 0.14757505 0.12772648]\n",
      " ...\n",
      " [0.00873664 0.02683789 0.09729988 ... 0.11934654 0.05534454 0.05542446]\n",
      " [0.07337632 0.065545   0.05230678 ... 0.16141652 0.14283478 0.16025962]\n",
      " [0.00270342 0.00262386 0.00292703 ... 0.00168895 0.00881386 0.0111219 ]]\n"
     ]
    }
   ],
   "source": [
    "for item in tfds.as_numpy(y2.map(get_mel)):\n",
    "    mel2 = item[\"audio\"]\n",
    "    \n",
    "print(mel2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff = mel - mel2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.10752817 -0.15116793 -0.33194444 ... -0.11363102 -0.08765338\n",
      "  -0.11615071]\n",
      " [-0.05809156 -0.01807318 -0.04802564 ... -0.02691042 -0.03997488\n",
      "  -0.11728518]\n",
      " [-0.09565531 -0.07997393 -0.0523121  ... -0.13209604 -0.1473766\n",
      "  -0.12745465]\n",
      " ...\n",
      " [-0.00741958 -0.00959427 -0.07699926 ... -0.11899713 -0.05489922\n",
      "  -0.05507677]\n",
      " [-0.07319769 -0.064216   -0.05000465 ... -0.16121633 -0.14231868\n",
      "  -0.16011143]\n",
      " [-0.00243318  0.00265434  0.01085539 ... -0.00108233 -0.00826479\n",
      "  -0.01081093]]\n"
     ]
    }
   ],
   "source": [
    "print(diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.12750958\n"
     ]
    }
   ],
   "source": [
    "print(np.abs(diff.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Melspectrograms show big differences."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "57fde4dc6cdb19e1d76ed7331772e4cf7a15b1a70b768f05e2959c60594bd89b"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "metadata": {
   "interpreter": {
    "hash": "57fde4dc6cdb19e1d76ed7331772e4cf7a15b1a70b768f05e2959c60594bd89b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
